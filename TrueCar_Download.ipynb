{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041e16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_car_links(listing_url, max_pages=1):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    all_links = []\n",
    "\n",
    "    for page in tqdm(range(1, max_pages + 1), desc=\"Extracting car links\"):\n",
    "        paginated_url = f\"{listing_url}&page={page}\"\n",
    "        response = requests.get(paginated_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        link_tags = soup.select('a[data-test=\"cardLinkCover\"]')\n",
    "        for tag in link_tags:\n",
    "            relative_link = tag.get(\"href\")\n",
    "            full_link = \"https://www.truecar.com\" + relative_link\n",
    "            all_links.append({\"url\": full_link})\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(\"./data/truecar_links.json\", \"w\") as f:\n",
    "        json.dump(all_links, f, indent=2)\n",
    "\n",
    "    # Save to CSV\n",
    "    pd.DataFrame(all_links).to_csv(\"./data/truecar_links.csv\", index=False)\n",
    "\n",
    "    print(f\"✅ Saved {len(all_links)} links to truecar_links.json and truecar_links.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b17b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_car_details(link):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    car_data = {'url': link}\n",
    "\n",
    "    try:\n",
    "        container = soup.select_one(\"div.row.pt-3\")\n",
    "        if container:\n",
    "            details = container.select(\"div.flex.items-center\")\n",
    "            for detail in details:\n",
    "                text = detail.get_text(separator=\" \", strip=True)\n",
    "                if \":\" in text:\n",
    "                    key, value = text.split(\":\", 1)\n",
    "                    car_data[key.strip().lower().replace(\" \", \"_\")] = value.strip()\n",
    "                elif \"VIN\" in text:\n",
    "                    car_data['vin'] = text.split(\"VIN:\")[1].strip()\n",
    "                elif \"Stock Number\" in text:\n",
    "                    car_data['stock_number'] = text.split(\"Stock Number:\")[1].strip()\n",
    "                elif \"miles\" in text:\n",
    "                    car_data['mileage'] = text.strip()\n",
    "                elif \"Listed\" in text:\n",
    "                    car_data['listed_since'] = text.strip()\n",
    "        # Options & packages\n",
    "        options_container = soup.find('h2', string=\"Options & packages\")\n",
    "        if options_container:\n",
    "            options_list = []\n",
    "            for item in options_container.find_next(\"div\").find_all(\"div\", class_=\"flex items-center\"):\n",
    "                text = item.get_text(strip=True)\n",
    "                if text:\n",
    "                    options_list.append(text)\n",
    "            car_data['options_and_packages'] = \", \".join(options_list)\n",
    "\n",
    "        # Popular Features\n",
    "        popular_container = soup.find('h2', string=\"Popular features\")\n",
    "        if popular_container:\n",
    "            features_list = []\n",
    "            for item in popular_container.find_next(\"div\").find_all(\"div\", class_=\"flex items-center\"):\n",
    "                text = item.get_text(strip=True)\n",
    "                if text:\n",
    "                    features_list.append(text)\n",
    "            car_data['popular_features'] = \", \".join(features_list)\n",
    "        standard_container = soup.find('h2', string=\"Standard features\")\n",
    "        if standard_container:\n",
    "            std_features_list = []\n",
    "            # The features typically follow in divs with 'flex items-center' class\n",
    "            for item in standard_container.find_next(\"div\").find_all(\"div\", class_=\"flex items-center\"):\n",
    "                text = item.get_text(strip=True)\n",
    "                if text:\n",
    "                    std_features_list.append(text)\n",
    "            car_data['standard_features'] = \", \".join(std_features_list)\n",
    "        price_section = soup.find('div', {'id': 'usedPriceGraph'})\n",
    "        if price_section:\n",
    "            # List and average price\n",
    "            line_items = price_section.select('div[data-test=\"usedListingPriceGraphLineItem\"]')\n",
    "            for item in line_items:\n",
    "                label = item.get(\"data-test-item\")\n",
    "                text = item.get_text(separator=\"|\", strip=True)\n",
    "                if label and \"|\" in text:\n",
    "                    _, value = text.split(\"|\")\n",
    "                    key = label.lower().replace(\" \", \"_\")\n",
    "                    car_data[key] = value.strip()\n",
    "\n",
    "            # Price Quality Bars (e.g., Excellent, Great, Fair, High)\n",
    "            quality_bars = price_section.select('div[data-test=\"priceRangeIconAndRange\"]')\n",
    "            for bar in quality_bars:\n",
    "                quality = bar.get(\"data-test-item\")\n",
    "                range_tag = bar.find(\"p\")\n",
    "                if quality and range_tag:\n",
    "                    car_data[f\"price_range_{quality.lower()}\"] = range_tag.text.strip()\n",
    "\n",
    "            # Summary sentence\n",
    "            description = price_section.find('div', {'data-test': 'usedListingPriceGraphDescription'})\n",
    "            if description:\n",
    "                car_data[\"price_description\"] = description.get_text(strip=True)\n",
    "        seller_notes_header = soup.find('h2', string=\"Seller Notes\")\n",
    "        if seller_notes_header:\n",
    "            seller_div = seller_notes_header.find_next('div', class_='see-more')\n",
    "            if seller_div:\n",
    "                notes = seller_div.get_text(separator=\" \", strip=True)\n",
    "                car_data['seller_notes'] = notes\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error extracting from {link}: {e}\")\n",
    "\n",
    "    return car_data\n",
    "\n",
    "def scrape_all_car_details(json_path=\"./data/truecar_links.json\", output_json=\"./data/truecar_details.json\", output_csv=\"./data/truecar_details.csv\"):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        car_links = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for entry in tqdm(car_links, desc=\"Scraping car details\"):\n",
    "        link = entry[\"url\"]\n",
    "        car_info = extract_car_details(link)\n",
    "        results.append(car_info)\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"✅ Saved car details to {output_json} and {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8d9100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting car links: 100%|██████████| 100/100 [02:42<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 3159 links to truecar_links.json and truecar_links.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping car details: 100%|██████████| 3159/3159 [1:02:19<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved car details to ./data/truecar_details.json and ./data/truecar_details.csv\n"
     ]
    }
   ],
   "source": [
    "listing_url = \"https://www.truecar.com/used-cars-for-sale/listings/location-boston-ma/?stock_type=used&page_size=100\"\n",
    "\n",
    "extract_car_links(listing_url, max_pages=100)  # Creates JSON + CSV of URLs  \n",
    "scrape_all_car_details()                     # Reads from JSON, creates JSON + CSV of details\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
